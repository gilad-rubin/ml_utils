{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.preprocessing import KBinsDiscretizer, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/AmesHousing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"SalePrice\"].copy()\n",
    "X = df.drop(\"SalePrice\", axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_categories(X, y, categorical_columns, scoring_function):\n",
    "    categories_sorted = {}\n",
    "    for col in categorical_columns:\n",
    "        category_scores = scoring_function(X[col], y)\n",
    "        sorted_categories = category_scores.sort_values().index.tolist()\n",
    "        categories_sorted[col] = sorted_categories\n",
    "    return categories_sorted\n",
    "\n",
    "# Scoring function for mean\n",
    "def mean_score(x, y):\n",
    "    return y.groupby(x).mean()\n",
    "\n",
    "# WoE scoring function\n",
    "def woe_score(x, y):\n",
    "    total_goods = y.sum()\n",
    "    total_bads = len(y) - total_goods\n",
    "    grouped = y.groupby(x).agg(['sum', 'count'])\n",
    "    grouped['goods'] = grouped['sum']\n",
    "    grouped['bads'] = grouped['count'] - grouped['goods']\n",
    "    grouped['woe'] = np.log((grouped['goods'] / total_goods) / (grouped['bads'] / total_bads))\n",
    "    return grouped['woe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_optimal_bins(X, max_bins=20, min_bins=2, factor=1.5):\n",
    "    n_bins = []\n",
    "    for column in X.columns:\n",
    "        if len(pd.unique(X[column])) < max_bins:\n",
    "            # For categorical data, use a default number of bins\n",
    "            n_bins_col = min(len(pd.unique(X[column]))-1, max_bins)\n",
    "            n_bins.append(max(min_bins, n_bins_col))\n",
    "        else:\n",
    "            Q1 = X[column].quantile(0.25)\n",
    "            Q3 = X[column].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            n = len(X[column].dropna())  # Exclude NaN values for the calculation\n",
    "            \n",
    "            # Calculate bin width using Freedman-Diaconis rule\n",
    "            bin_width = factor * IQR / (n ** (1/3))\n",
    "            \n",
    "            # Calculate number of bins\n",
    "            if bin_width > 0:\n",
    "                optimal_bins = int((X[column].max() - X[column].min()) / bin_width)\n",
    "                optimal_bins = max(min(optimal_bins, max_bins), min_bins)\n",
    "            else:\n",
    "                optimal_bins = min_bins\n",
    "            \n",
    "            n_bins.append(optimal_bins)\n",
    "            \n",
    "    return n_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get categorical and numeric columns\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort categories by the mean of the target\n",
    "sorted_categories = sort_categories(X, y, cat_cols, mean_score)\n",
    "categories = [sorted_categories[col] for col in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=np.nan)\n",
    "X_copy = X.copy()\n",
    "X_copy[cat_cols] = ordinal_encoder.fit_transform(X_copy[cat_cols])\n",
    "\n",
    "# Calculate optimal bins\n",
    "optimal_bins = calculate_optimal_bins(X_copy, max_bins=100)\n",
    "#print(f\"Optimal bins: {optimal_bins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the code before has been run, and X_copy is already defined with categorical columns encoded\n",
    "quantile_cuts = {}\n",
    "for col in X_copy.columns:\n",
    "    try:\n",
    "        # Attempt to use the number of bins specified for each column, fall back to a default if any error\n",
    "        num_bins = optimal_bins[X_copy.columns.get_loc(col)]\n",
    "        quantile_cuts[col] = pd.qcut(X_copy[col], q=num_bins, duplicates='drop')\n",
    "    except (ValueError, TypeError):\n",
    "        print(f\"Skipping column {col} due to an error with binning.\")\n",
    "\n",
    "# The result is a dictionary of Series, each transformed into quantile bins\n",
    "# You might want to convert this dictionary back to a DataFrame:\n",
    "transformed_data = pd.DataFrame(quantile_cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (y >=y.quantile(0.75)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule: Pool QC <= 2.0, Score: 0.8472978603872034, Recall: 0.009536784741144414, Precision: 0.7\n",
      "Rule: Exter Qual <= 2.0, Score: 0.2291137183007135, Recall: 0.8583106267029973, Precision: 0.5570291777188329\n",
      "Rule: PID <= 528477022.5, Score: -0.040933408926252995, Recall: 0.4891008174386921, Precision: 0.4897680763983629\n",
      "Rule: Mas Vnr Area > 96.391, Score: -0.08701137698962969, Recall: 0.014986376021798364, Precision: 0.4782608695652174\n",
      "Rule: Mas Vnr Area isna(), Score: -0.08701137698962969, Recall: 0.014986376021798364, Precision: 0.4782608695652174\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "class RuleEvaluator:\n",
    "    def __init__(self, min_samples, max_samples, min_precision, scorer):\n",
    "        self.min_samples = min_samples\n",
    "        self.max_samples = max_samples\n",
    "        self.min_precision = min_precision\n",
    "        self.scorer = scorer\n",
    "\n",
    "    def evaluate(self, y, mask):\n",
    "        count = mask.sum()\n",
    "        if count < self.min_samples or count > self.max_samples:\n",
    "            return None\n",
    "        \n",
    "        y_pred = mask.astype(int)\n",
    "        recall = recall_score(y, y_pred, zero_division=0)\n",
    "        precision = precision_score(y, y_pred, zero_division=0)\n",
    "        \n",
    "        if recall >= self.min_samples / len(y) and precision >= self.min_precision:\n",
    "            rule_score = self.scorer(y[mask]) if self.scorer else 0\n",
    "            return RuleResult(rule_score, recall, precision)\n",
    "        return None\n",
    "\n",
    "class RuleResult:\n",
    "    def __init__(self, score, recall, precision):\n",
    "        self.score = score\n",
    "        self.recall = recall\n",
    "        self.precision = precision\n",
    "\n",
    "    def is_relevant(self):\n",
    "        return self.score is not None\n",
    "\n",
    "def create_rule_mask(X, col, value, operator):\n",
    "    def check_interval(interval, value, operator):\n",
    "        if operator == \"<=\":\n",
    "            return interval.right <= value\n",
    "        elif operator == \">=\":\n",
    "            return interval.left >= value\n",
    "        return False\n",
    "\n",
    "    mask = X[col].apply(lambda x: check_interval(x, value, operator)).astype(bool)\n",
    "    return pd.Series(np.where(mask==True, True, False))\n",
    "\n",
    "def process_column(X, y, col, rule_evaluator):\n",
    "    results = []\n",
    "    categories = X[col].cat.categories\n",
    "\n",
    "    for category in categories:\n",
    "        lower_edge, upper_edge = category.left, category.right\n",
    "\n",
    "        rules = [\n",
    "            (f\"{col} <= {upper_edge}\", create_rule_mask(X, col, upper_edge, \"<=\")),\n",
    "            (f\"{col} > {lower_edge}\", create_rule_mask(X, col, lower_edge, \">\"))\n",
    "        ]\n",
    "\n",
    "        for rule, mask in rules:\n",
    "            result = rule_evaluator.evaluate(y, mask)\n",
    "            if result and result.is_relevant():\n",
    "                results.append((rule, result))\n",
    "\n",
    "    nan_mask = X[col].isna()\n",
    "    if nan_mask.any():\n",
    "        nan_result = rule_evaluator.evaluate(y, nan_mask)\n",
    "        if nan_result and nan_result.is_relevant():\n",
    "            results.append((f\"{col} isna()\", nan_result))\n",
    "\n",
    "    return results\n",
    "\n",
    "def find_top_k_rules(X, y, k, rule_evaluator):\n",
    "    min_heap = []\n",
    "    for col in X.columns:\n",
    "        results = process_column(X, y, col, rule_evaluator)\n",
    "        for rule, result in results:\n",
    "            heapq.heappush(min_heap, (result.score, rule, result))\n",
    "            if len(min_heap) > k:\n",
    "                heapq.heappop(min_heap)\n",
    "\n",
    "    top_k_rules = sorted(min_heap, key=lambda x: -x[0])  # Sorting by score descending\n",
    "    return [(score, rule, res.recall, res.precision) for score, rule, res in top_k_rules]\n",
    "\n",
    "# Example usage\n",
    "scorer = lambda y: np.log(np.mean(y) / (1 - np.mean(y))) if np.mean(y) not in [0, 1] else float('-inf')\n",
    "rule_evaluator = RuleEvaluator(min_samples=10, max_samples=len(X)-10, min_precision=0.01, scorer=scorer)\n",
    "top_k_rules = find_top_k_rules(X, y, 5, rule_evaluator)  # Top 5 rules\n",
    "\n",
    "for score, rule, recall, precision in top_k_rules:\n",
    "    print(f\"Rule: {rule}, Score: {score}, Recall: {recall}, Precision: {precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exter Qual in ['Ex', 'Fa', 'Gd']\n",
      "Pool QC in ['Ex', 'Fa', 'Gd']\n"
     ]
    }
   ],
   "source": [
    "def convert_rules_to_categories(rules, encoder_categories, feature_names):\n",
    "    categorical_rules = []\n",
    "    for rule, result in rules:\n",
    "        # Parsing the rule into components\n",
    "        match = re.match(r\"(.+?)\\s*(<=|>=|>|<|==|!=)\\s*(.*)\", rule)\n",
    "        if not match:\n",
    "            print(f\"Could not parse rule: {rule}\")\n",
    "            continue\n",
    "\n",
    "        feature_name, operation, encoded_value = match.groups()\n",
    "\n",
    "        # Find the category list for the feature from the encoder\n",
    "        if feature_name in feature_names:\n",
    "            cat_index = feature_names.index(feature_name)\n",
    "            original_categories = encoder_categories[cat_index]\n",
    "            \n",
    "            # Convert the encoded value back to an integer index (if necessary)\n",
    "            if encoded_value.isdigit():\n",
    "                value_index = int(encoded_value)\n",
    "            else:\n",
    "                # Find index if encoded_value is a label\n",
    "                value_index = np.where(original_categories == encoded_value)[0][0]\n",
    "\n",
    "            # Determine relevant categories based on the operation\n",
    "            if operation in [\"<=\", \"==\"]:\n",
    "                relevant_categories = original_categories[:value_index + 1]\n",
    "            elif operation == \"<\":\n",
    "                relevant_categories = original_categories[:value_index]\n",
    "            elif operation == \">=\":\n",
    "                relevant_categories = original_categories[value_index:]\n",
    "            elif operation == \">\":\n",
    "                relevant_categories = original_categories[value_index + 1:]\n",
    "\n",
    "            # Format the rule using category labels\n",
    "            category_list = \", \".join([f\"'{cat}'\" for cat in relevant_categories])\n",
    "            if category_list:\n",
    "                new_rule = f\"{feature_name} in [{category_list}]\"\n",
    "            else:\n",
    "                new_rule = f\"{feature_name} is empty\"\n",
    "        else:\n",
    "            new_rule = rule  # Non-categorical rule remains unchanged\n",
    "\n",
    "        categorical_rules.append((new_rule, result))\n",
    "\n",
    "    return categorical_rules\n",
    "\n",
    "# Example usage assuming the previous setup\n",
    "feature_names = X[cat_cols].columns.tolist()  # Assuming cat_cols has the categorical columns\n",
    "rules = [(\"Exter Qual <= 2\", \"result\"), (\"Pool QC <= 2\", \"result\")]  # Example rules from encoded data\n",
    "\n",
    "# Convert rules back to categorical labels\n",
    "categorical_rules = convert_rules_to_categories(rules, ordinal_encoder.categories_, feature_names)\n",
    "\n",
    "# Print the rules\n",
    "for rule, _ in categorical_rules:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age > 19.999\n",
      "age > 48.0\n",
      "age > 34.0\n",
      "age <= 34.0\n",
      "age <= 59.0\n",
      "age <= 48.0\n",
      "salary > 55655.496\n",
      "salary > 45522.726\n",
      "salary > 22052.444\n",
      "salary <= 70617.815\n",
      "salary <= 55655.496\n",
      "salary <= 45522.726\n",
      "category > -0.001\n",
      "category > 1.0\n",
      "category <= 1.0\n",
      "category <= 2.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import bisect\n",
    "\n",
    "class PandasQCutDiscretizer:\n",
    "    def __init__(self, n_bins=3):\n",
    "        self.n_bins = n_bins\n",
    "        self.left_edges = {}\n",
    "        self.right_edges = {}\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in X.columns:\n",
    "            if X[col].dtype in [np.float64, np.int64]:  # We only discretize numeric columns\n",
    "                X[col] = pd.qcut(X[col], self.n_bins, duplicates='drop') #TODO: handle bins where nunique <= n_bins\n",
    "                self.left_edges[col] = [bin.left for bin in X[col].unique()]\n",
    "                self.right_edges[col] = [bin.right for bin in X[col].unique()]\n",
    "        return X\n",
    "\n",
    "    def get_bin_edges(self):\n",
    "        return self.bin_edges\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self):\n",
    "        self.encoder = OrdinalEncoder()\n",
    "        self.category_mappings = {}\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in X.select_dtypes(include=['category', 'object']).columns:\n",
    "            original_categories = list(X[col].cat.categories)\n",
    "            X[col] = self.encoder.fit_transform(X[[col]])[:, 0]\n",
    "            self.category_mappings[col] = original_categories\n",
    "        return X\n",
    "\n",
    "    def convert_to_categorical(self, feature, value, is_lower_bound):\n",
    "        categories = self.category_mappings.get(feature, [])\n",
    "        index = int(value)  # Assuming value is already the correct integer index\n",
    "\n",
    "        if index >= len(categories):  # Ensure the index does not exceed the last category\n",
    "            index = len(categories) - 1\n",
    "        if index < 0:  # Ensure the index is not negative\n",
    "            index = 0\n",
    "\n",
    "        if is_lower_bound:\n",
    "            # Generates a rule for values in categories from index+1 to the end\n",
    "            return f\"{feature} in {categories[index + 1:]}\"\n",
    "        else:\n",
    "            # Generates a rule for values in categories from the start up to index\n",
    "            return f\"{feature} in {categories[:index + 1]}\"\n",
    "\n",
    "\n",
    "class RuleGenerator:\n",
    "    def __init__(self, discretizer, encoder):\n",
    "        self.discretizer = discretizer\n",
    "        self.encoder = encoder\n",
    "\n",
    "    def generate_all_rules(self, X):\n",
    "        rules = []\n",
    "        for feature in X.columns:\n",
    "            left_edges = discretizer.left_edges[feature]\n",
    "            right_edges = discretizer.right_edges[feature]\n",
    "            rules += [f\"{feature} > {edge}\" for edge in left_edges]\n",
    "            rules += [f\"{feature} <= {edge}\" for edge in right_edges]\n",
    "            \n",
    "            if X[feature].isna().any():\n",
    "                rules += f\"{feature}.isna()\"\n",
    "            \n",
    "        return rules\n",
    "\n",
    "data = {\n",
    "    'age': np.random.randint(20, 60, 100),\n",
    "    'salary': np.random.normal(50000, 12000, 100),\n",
    "    'category': ['group' + str(i % 3) for i in range(100)]\n",
    "}\n",
    "X = pd.DataFrame(data)\n",
    "X['category'] = X['category'].astype('category')\n",
    "\n",
    "# Initialize components\n",
    "encoder = Encoder()\n",
    "discretizer = PandasQCutDiscretizer()\n",
    "\n",
    "# Process data\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "X_preprocessed = discretizer.fit_transform(X_encoded)\n",
    "\n",
    "# Generate rules\n",
    "rule_generator = RuleGenerator(discretizer, encoder)\n",
    "rules = rule_generator.generate_all_rules(X_preprocessed)\n",
    "\n",
    "for rule in rules:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuleGenerator:\n",
    "    def __init__(self, discretizer, encoder):\n",
    "        self.discretizer = discretizer\n",
    "        self.encoder = encoder\n",
    "\n",
    "    def generate_all_rules(self, X):\n",
    "        rules = []\n",
    "        for feature in X.columns:\n",
    "            left_edges = self.discretizer.left_edges[feature]\n",
    "            right_edges = self.discretizer.right_edges[feature]\n",
    "            rules += [Rule(feature, '>', edge) for edge in left_edges]\n",
    "            rules += [Rule(feature, '<=', edge) for edge in right_edges]\n",
    "            \n",
    "            if X[feature].isna().any():\n",
    "                rules.append(Rule(feature, 'isna', None))\n",
    "            \n",
    "        return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'age': np.random.randint(20, 60, 100),\n",
    "    'salary': np.random.normal(50000, 12000, 100),\n",
    "    'category': ['group' + str(i % 3) for i in range(100)],\n",
    "    'target': np.random.randint(0, 2, 100)  # Binary target variable\n",
    "}\n",
    "X = pd.DataFrame(data)\n",
    "y = X['target']\n",
    "X['category'] = X['category'].astype('category')\n",
    "X.drop('target', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "class PandasQCutDiscretizer:\n",
    "    def __init__(self, n_bins=3):\n",
    "        self.n_bins = n_bins\n",
    "        self.left_edges = {}\n",
    "        self.right_edges = {}\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in X.columns:\n",
    "            if X[col].dtype in [np.float64, np.int64]:  # We only discretize numeric columns\n",
    "                X[col] = pd.qcut(X[col], self.n_bins, duplicates='drop')\n",
    "                self.left_edges[col] = [bin.left for bin in X[col].unique()]\n",
    "                self.right_edges[col] = [bin.right for bin in X[col].unique()]\n",
    "        return X\n",
    "\n",
    "    def get_bin_edges(self):\n",
    "        return self.left_edges, self.right_edges\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self):\n",
    "        self.encoder = OrdinalEncoder()\n",
    "        self.category_mappings = {}\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in X.select_dtypes(include=['category', 'object']).columns:\n",
    "            original_categories = list(X[col].cat.categories)\n",
    "            X[col] = self.encoder.fit_transform(X[[col]])[:, 0]\n",
    "            self.category_mappings[col] = original_categories\n",
    "        return X\n",
    "\n",
    "    def convert_to_categorical(self, feature, value, is_lower_bound):\n",
    "        categories = self.category_mappings.get(feature, [])\n",
    "        index = int(value)  # Assuming value is already the correct integer index\n",
    "\n",
    "        if index >= len(categories):  # Ensure the index does not exceed the last category\n",
    "            index = len(categories) - 1\n",
    "        if index < 0:  # Ensure the index is not negative\n",
    "            index = 0\n",
    "\n",
    "        if is_lower_bound:\n",
    "            return f\"{feature} in {categories[index + 1:]}\"\n",
    "        else:\n",
    "            return f\"{feature} in {categories[:index + 1]}\"\n",
    "\n",
    "def negate_last_rule(path):\n",
    "    if path.rules:\n",
    "        new_rules = path.rules[:-1] + [path.rules[-1].negate_rule()]\n",
    "        return Path(new_rules)\n",
    "    return path\n",
    "\n",
    "class Rule:\n",
    "    def __init__(self, feature, operator, value, score=0):\n",
    "        self.feature = feature\n",
    "        self.operator = operator\n",
    "        self.value = value\n",
    "        self.score = score\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.feature} {self.operator} {self.value}\"\n",
    "\n",
    "    def get_mask(self, X):\n",
    "        if self.operator in ['isna', 'notnull']:\n",
    "            if self.operator == 'isna':\n",
    "                return X[self.feature].isna()\n",
    "            else:\n",
    "                return X[self.feature].notnull()\n",
    "        else:\n",
    "            return eval(f\"X['{self.feature}'] {self.operator} {self.value}\")\n",
    "\n",
    "    def negate_rule(self):\n",
    "        negation_map = {'<=': '>', '>=': '<', '<': '>=', '>': '<=', '==': '!=', '!=': '==', 'isna': 'notnull', 'notnull': 'isna'}\n",
    "        new_operator = negation_map[self.operator]\n",
    "        return Rule(self.feature, new_operator, self.value)\n",
    "\n",
    "class RuleGenerator:\n",
    "    def __init__(self, discretizer):\n",
    "        self.discretizer = discretizer\n",
    "\n",
    "    def generate_all_rules(self, X):\n",
    "        rules = []\n",
    "        for feature in X.columns:\n",
    "            left_edges = self.discretizer.left_edges[feature]\n",
    "            right_edges = self.discretizer.right_edges[feature]\n",
    "            rules += [Rule(feature, '>', edge) for edge in left_edges]\n",
    "            rules += [Rule(feature, '<=', edge) for edge in right_edges]\n",
    "            \n",
    "            if X[feature].isna().any():\n",
    "                rules.append(Rule(feature, 'isna', None))\n",
    "            \n",
    "        return rules\n",
    "\n",
    "class Path:\n",
    "    def __init__(self, rules=None):\n",
    "        self.rules = rules if rules is not None else []\n",
    "\n",
    "    def get_mask(self, X):\n",
    "        mask = np.ones(len(X), dtype=bool)\n",
    "        for rule in self.rules:\n",
    "            mask &= rule.get_mask(X)\n",
    "        return mask\n",
    "\n",
    "    def get_path_rule(self):\n",
    "        return \" and \".join([str(rule) for rule in self.rules])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Path: \" + \" and \".join([str(rule) for rule in self.rules])\n",
    "\n",
    "class BinaryRuleScore:\n",
    "    def __init__(self, recall, precision, WoE):\n",
    "        self.recall = recall\n",
    "        self.precision = precision\n",
    "        self.WoE = WoE\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"BinaryRuleScore (Recall: {self.recall}, Precision: {self.precision}, WoE: {self.WoE})\"\n",
    "\n",
    "class BinaryRuleEvaluator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def evaluate(self, rule, X, y):\n",
    "        mask = rule.get_mask(X)\n",
    "        \n",
    "        true_positives = y[mask].sum()\n",
    "        total_positives = y.sum()\n",
    "        predicted_positives = mask.sum()\n",
    "        total_cases = len(y)\n",
    "\n",
    "        recall = true_positives / total_positives if total_positives != 0 else 0\n",
    "        precision = true_positives / predicted_positives if predicted_positives != 0 else 0\n",
    "\n",
    "        total_negatives = total_cases - total_positives\n",
    "        false_positives = predicted_positives - true_positives\n",
    "        WoE = np.log((true_positives / total_positives) / (false_positives / total_negatives)) if false_positives and total_negatives else float('-inf')\n",
    "\n",
    "        return BinaryRuleScore(recall, precision, WoE)\n",
    "\n",
    "class RuleFilter:\n",
    "    def __init__(self, min_recall, min_precision, min_WoE):\n",
    "        self.min_recall = min_recall\n",
    "        self.min_precision = min_precision\n",
    "        self.min_WoE = min_WoE\n",
    "\n",
    "    def apply(self, rule_score):\n",
    "        return (rule_score.recall >= self.min_recall and\n",
    "                rule_score.precision >= self.min_precision and\n",
    "                rule_score.WoE >= self.min_WoE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: age <= 47.0\n",
      "Path: age <= 47.0 and salary <= 56531.954\n",
      "Path: age <= 47.0 and salary <= 56531.954 and category > 1.0\n",
      "Path: age <= 47.0 and salary <= 56531.954 and category > 1.0 and age > 35.0\n",
      "Path: age <= 47.0 and salary <= 56531.954 and category <= 1.0 and salary <= 46120.581\n",
      "Path: age <= 47.0 and salary <= 56531.954 and category <= 1.0 and salary <= 46120.581 and age <= 35.0\n",
      "Path: age <= 47.0 and salary <= 56531.954 and category <= 1.0 and salary > 46120.581 and age > 35.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Distinguisher:\n",
    "    def __init__(self, encoder, discretizer, rule_generator, evaluator):\n",
    "        self.encoder = encoder\n",
    "        self.discretizer = discretizer\n",
    "        self.rule_generator = rule_generator\n",
    "        self.evaluator = evaluator\n",
    "        self.rules = []\n",
    "    \n",
    "    def find_rules_recursive(self, X, y, chosen_rules, applied_path, rule_filter, best_score=float('-inf')):\n",
    "        #print(f\"Evaluating with applied path: {applied_path}\")\n",
    "        \n",
    "        applied_rules = [] if applied_path is None else applied_path.rules\n",
    "        evaluated_rules = []\n",
    "        for rule in self.all_rules:\n",
    "            rule_combination = Path(applied_rules + [rule])\n",
    "            rule_score = self.evaluator.evaluate(rule_combination, X, y)\n",
    "            #print(rule_combination, rule_score)\n",
    "            evaluated_rules.append((rule_combination, rule_score))\n",
    "\n",
    "        # Filter rules based on evaluation\n",
    "        filtered_rules = [rule for rule in evaluated_rules if rule_filter.apply(rule[1])]\n",
    "        if not filtered_rules:\n",
    "            print(\"No valid rules after filtering.\")\n",
    "            return chosen_rules\n",
    "\n",
    "        best_rule = max(filtered_rules, key=lambda x: x[1].WoE) # Use WoE as the primary score metric\n",
    "        current_best_score = best_rule[1].WoE\n",
    "        best_rule = best_rule[0]\n",
    "        \n",
    "        if current_best_score > best_score:\n",
    "            chosen_rules.append(best_rule)\n",
    "            print(best_rule)\n",
    "            # Recursive calls to explore with and without the best new rule added\n",
    "            self.find_rules_recursive(X, y, chosen_rules, best_rule, rule_filter, current_best_score)\n",
    "            neg_rule = negate_last_rule(best_rule)\n",
    "            neg_score = self.evaluator.evaluate(neg_rule, X, y)\n",
    "            if rule_filter.apply(neg_score):\n",
    "                chosen_rules.append(best_rule)\n",
    "                self.find_rules_recursive(X, y, chosen_rules, neg_rule, rule_filter, neg_score.WoE)\n",
    "        \n",
    "        return chosen_rules\n",
    "\n",
    "    def find_rules(self, X, y, rule_filter):\n",
    "        X_encoded = self.encoder.fit_transform(X)\n",
    "        X_preprocessed = self.discretizer.fit_transform(X_encoded)\n",
    "        \n",
    "        self.all_rules = self.rule_generator.generate_all_rules(X_preprocessed)\n",
    "        \n",
    "        chosen_rules = []\n",
    "        applied_path = None\n",
    "        \n",
    "        self.final_rules = self.find_rules_recursive(X_encoded, y, chosen_rules, applied_path, rule_filter)\n",
    "\n",
    "    def plot_rules_tree(self):\n",
    "        for rule_set, score in self.rules:\n",
    "            rule_descriptions = \" and \".join([str(rule) for rule in rule_set])\n",
    "            print(f\"Rules: {rule_descriptions}, Score: {score}\")\n",
    "\n",
    "encoder = Encoder()\n",
    "discretizer = PandasQCutDiscretizer()\n",
    "rule_generator = RuleGenerator(discretizer)\n",
    "evaluator = BinaryRuleEvaluator()\n",
    "rule_filter = RuleFilter(min_recall=0.1, min_precision=0.2, min_WoE=0.01)\n",
    "\n",
    "distinguisher = Distinguisher(encoder, discretizer, rule_generator, evaluator)\n",
    "distinguisher.find_rules(X, y, rule_filter)\n",
    "#distinguisher.plot_rules_tree(chosen_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path: age <= 47.0,\n",
       " Path: age <= 47.0 and salary <= 56531.954,\n",
       " Path: age <= 47.0 and salary <= 56531.954 and category > 1.0,\n",
       " Path: age <= 47.0 and salary <= 56531.954 and category > 1.0 and age > 35.0,\n",
       " Path: age <= 47.0 and salary <= 56531.954 and category > 1.0,\n",
       " Path: age <= 47.0 and salary <= 56531.954 and category <= 1.0 and salary <= 46120.581,\n",
       " Path: age <= 47.0 and salary <= 56531.954 and category <= 1.0 and salary <= 46120.581 and age <= 35.0,\n",
       " Path: age <= 47.0 and salary <= 56531.954 and category <= 1.0 and salary <= 46120.581 and age <= 35.0,\n",
       " Path: age <= 47.0 and salary <= 56531.954 and category <= 1.0 and salary <= 46120.581,\n",
       " Path: age <= 47.0 and salary <= 56531.954 and category <= 1.0 and salary > 46120.581 and age > 35.0]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinguisher.final_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rule:\n",
    "    def __init__(self, feature, operator, value, score=0):\n",
    "        self.feature = feature\n",
    "        self.operator = operator\n",
    "        self.value = value\n",
    "        self.score = score\n",
    "\n",
    "    def get_mask(self, X):\n",
    "        if self.operator in ['isna', 'notnull']:\n",
    "            if self.operator == 'isna':\n",
    "                return X[self.feature].isna()\n",
    "            else:\n",
    "                return X[self.feature].notnull()\n",
    "        else:\n",
    "            if pd.api.types.is_categorical_dtype(X[self.feature]):\n",
    "                # Convert categorical comparison to work with category codes\n",
    "                cat_value = X[self.feature].cat.categories.get_loc(self.value)\n",
    "                return eval(f\"X['{self.feature}'].cat.codes {self.operator} {cat_value}\")\n",
    "            else:\n",
    "                return eval(f\"X['{self.feature}'] {self.operator} {self.value}\")\n",
    "\n",
    "    def negate_rule(self):\n",
    "        negation_map = {'<=': '>', '>=': '<', '<': '>=', '>': '<=', '==': '!=', '!=': '==', 'isna': 'notnull', 'notnull': 'isna'}\n",
    "        new_operator = negation_map[self.operator]\n",
    "        return Rule(self.feature, new_operator, self.value)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.feature} {self.operator} {self.value}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Path:\n",
    "    def __init__(self, rules=None):\n",
    "        self.rules = rules if rules is not None else []\n",
    "\n",
    "    def get_mask(self, X):\n",
    "        mask = np.ones(len(X), dtype=bool)\n",
    "        for rule in self.rules:\n",
    "            mask &= rule.get_mask(X)\n",
    "        return mask\n",
    "\n",
    "    def get_path_rule(self):\n",
    "        return \" and \".join([str(rule) for rule in self.rules])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Path: \" + \" and \".join([str(rule) for rule in self.rules])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class BinaryRuleScore:\n",
    "    def __init__(self, recall, precision, WoE):\n",
    "        self.recall = recall\n",
    "        self.precision = precision\n",
    "        self.WoE = WoE\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"BinaryRuleScore (Recall: {self.recall}, Precision: {self.precision}, WoE: {self.WoE})\"\n",
    "\n",
    "class BinaryRuleEvaluator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def evaluate(self, rule, X, y):\n",
    "        # Evaluating a rule assumes that rule.get_mask(X) is a method provided within the rule object\n",
    "        mask = rule.get_mask(X)\n",
    "        \n",
    "        true_positives = y[mask].sum()\n",
    "        total_positives = y.sum()\n",
    "        predicted_positives = mask.sum()\n",
    "        total_cases = len(y)\n",
    "\n",
    "        recall = true_positives / total_positives if total_positives != 0 else 0\n",
    "        precision = true_positives / predicted_positives if predicted_positives != 0 else 0\n",
    "\n",
    "        total_negatives = total_cases - total_positives\n",
    "        false_positives = predicted_positives - true_positives\n",
    "        WoE = np.log((true_positives / total_positives) / (false_positives / total_negatives)) if false_positives and total_negatives else float('-inf')\n",
    "\n",
    "        return BinaryRuleScore(recall, precision, WoE)\n",
    "\n",
    "class RuleFilter:\n",
    "    def __init__(self, min_recall, min_precision, min_WoE):\n",
    "        self.min_recall = min_recall\n",
    "        self.min_precision = min_precision\n",
    "        self.min_WoE = min_WoE\n",
    "\n",
    "    def apply(self, rule_score):\n",
    "        # Filter based on the provided minima for recall, precision, and WoE\n",
    "        return (rule_score.recall >= self.min_recall and\n",
    "                rule_score.precision >= self.min_precision and\n",
    "                rule_score.WoE >= self.min_WoE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distinguisher:\n",
    "    def __init__(self, preprocessor, rule_generator, evaluator):\n",
    "        self.preprocessor = preprocessor\n",
    "        self.rule_generator = rule_generator\n",
    "        self.evaluator = evaluator\n",
    "        self.rules = []\n",
    "\n",
    "    def find_rules_recursive(self, X, y, chosen_rules, applied_rules, rule_filter):\n",
    "        mask = np.ones(len(X), dtype=bool)\n",
    "        for rule in applied_rules:\n",
    "            mask &= rule.get_mask(X)\n",
    "        X_sub = X[mask]\n",
    "        y_sub = y[mask]\n",
    "\n",
    "        if len(X_sub) == 0:\n",
    "            chosen_rules.append((applied_rules, None))\n",
    "            return chosen_rules\n",
    "\n",
    "        rules = self.rule_generator.generate_all_rules(X_sub)\n",
    "        if not rules:\n",
    "            chosen_rules.append((applied_rules, None))\n",
    "            return chosen_rules\n",
    "\n",
    "        evaluated_rules = [(rule, self.evaluator.evaluate(rule, X_sub, y_sub)) for rule in rules]\n",
    "\n",
    "        best_rule = max(evaluated_rules, key=lambda x: x[1].WoE)  # Use WoE as the primary score metric\n",
    "\n",
    "        if rule_filter.apply(best_rule[1]):\n",
    "            new_applied_rules = applied_rules + [best_rule[0]]\n",
    "            self.find_rules_recursive(X, y, chosen_rules, new_applied_rules, rule_filter)\n",
    "            self.find_rules_recursive(X, y, chosen_rules, new_applied_rules + [best_rule[0].negate_rule()], rule_filter)\n",
    "        else:\n",
    "            chosen_rules.append((applied_rules, best_rule[1]))\n",
    "\n",
    "        return chosen_rules\n",
    "\n",
    "    def find_rules(self, X, y, rule_filter):\n",
    "        chosen_rules = []\n",
    "        applied_rules = []\n",
    "        final_rules = self.find_rules_recursive(X, y, chosen_rules, applied_rules, rule_filter)\n",
    "        self.rules = [rule for rule in final_rules if rule_filter.apply(rule[1])]\n",
    "        return self.rules\n",
    "\n",
    "    def plot_rules_tree(self):\n",
    "        for rule_set, score in self.rules:\n",
    "            rule_descriptions = \" and \".join([str(rule) for rule in rule_set])\n",
    "            print(f\"Rules: {rule_descriptions}, Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[331], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m     distinguisher\u001b[39m.\u001b[39mplot_rules_tree()\n\u001b[1;32m     26\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[331], line 23\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m rule_generator \u001b[39m=\u001b[39m RuleGenerator(discretizer, encoder)\n\u001b[1;32m     22\u001b[0m distinguisher \u001b[39m=\u001b[39m Distinguisher(discretizer, rule_generator, evaluator)\n\u001b[0;32m---> 23\u001b[0m rules \u001b[39m=\u001b[39m distinguisher\u001b[39m.\u001b[39;49mfind_rules(X_preprocessed, y, \u001b[39mfilter\u001b[39;49m)\n\u001b[1;32m     24\u001b[0m distinguisher\u001b[39m.\u001b[39mplot_rules_tree()\n",
      "Cell \u001b[0;32mIn[329], line 40\u001b[0m, in \u001b[0;36mDistinguisher.find_rules\u001b[0;34m(self, X, y, rule_filter)\u001b[0m\n\u001b[1;32m     38\u001b[0m chosen_rules \u001b[39m=\u001b[39m []\n\u001b[1;32m     39\u001b[0m applied_rules \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 40\u001b[0m final_rules \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_rules_recursive(X, y, chosen_rules, applied_rules, rule_filter)\n\u001b[1;32m     41\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrules \u001b[39m=\u001b[39m [rule \u001b[39mfor\u001b[39;00m rule \u001b[39min\u001b[39;00m final_rules \u001b[39mif\u001b[39;00m rule_filter\u001b[39m.\u001b[39mapply(rule[\u001b[39m1\u001b[39m])]\n\u001b[1;32m     42\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrules\n",
      "Cell \u001b[0;32mIn[329], line 24\u001b[0m, in \u001b[0;36mDistinguisher.find_rules_recursive\u001b[0;34m(self, X, y, chosen_rules, applied_rules, rule_filter)\u001b[0m\n\u001b[1;32m     21\u001b[0m     chosen_rules\u001b[39m.\u001b[39mappend((applied_rules, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m chosen_rules\n\u001b[0;32m---> 24\u001b[0m evaluated_rules \u001b[39m=\u001b[39m [(rule, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluator\u001b[39m.\u001b[39mevaluate(rule, X_sub, y_sub)) \u001b[39mfor\u001b[39;00m rule \u001b[39min\u001b[39;00m rules]\n\u001b[1;32m     26\u001b[0m best_rule \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(evaluated_rules, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mWoE)  \u001b[39m# Use WoE as the primary score metric\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39mif\u001b[39;00m rule_filter\u001b[39m.\u001b[39mapply(best_rule[\u001b[39m1\u001b[39m]):\n",
      "Cell \u001b[0;32mIn[329], line 24\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m     chosen_rules\u001b[39m.\u001b[39mappend((applied_rules, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m chosen_rules\n\u001b[0;32m---> 24\u001b[0m evaluated_rules \u001b[39m=\u001b[39m [(rule, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluator\u001b[39m.\u001b[39;49mevaluate(rule, X_sub, y_sub)) \u001b[39mfor\u001b[39;00m rule \u001b[39min\u001b[39;00m rules]\n\u001b[1;32m     26\u001b[0m best_rule \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(evaluated_rules, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mWoE)  \u001b[39m# Use WoE as the primary score metric\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39mif\u001b[39;00m rule_filter\u001b[39m.\u001b[39mapply(best_rule[\u001b[39m1\u001b[39m]):\n",
      "Cell \u001b[0;32mIn[328], line 19\u001b[0m, in \u001b[0;36mBinaryRuleEvaluator.evaluate\u001b[0;34m(self, rule, X, y)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39mself\u001b[39m, rule, X, y):\n\u001b[1;32m     18\u001b[0m     \u001b[39m# Evaluating a rule assumes that rule.get_mask(X) is a method provided within the rule object\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     mask \u001b[39m=\u001b[39m rule\u001b[39m.\u001b[39;49mget_mask(X)\n\u001b[1;32m     21\u001b[0m     true_positives \u001b[39m=\u001b[39m y[mask]\u001b[39m.\u001b[39msum()\n\u001b[1;32m     22\u001b[0m     total_positives \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39msum()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get_mask'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    data = {\n",
    "        'age': np.random.randint(20, 60, 100),\n",
    "        'salary': np.random.normal(50000, 12000, 100),\n",
    "        'category': ['group' + str(i % 3) for i in range(100)],\n",
    "        'target': np.random.randint(0, 2, 100)  # Binary target variable\n",
    "    }\n",
    "    X = pd.DataFrame(data)\n",
    "    y = X['target']\n",
    "    X['category'] = X['category'].astype('category')\n",
    "    X.drop('target', axis=1, inplace=True)\n",
    "\n",
    "    encoder = Encoder()\n",
    "    discretizer = PandasQCutDiscretizer()\n",
    "    evaluator = BinaryRuleEvaluator()\n",
    "    filter = RuleFilter(min_recall=0.3, min_precision=0.2, min_WoE=0.01)\n",
    "\n",
    "    X_encoded = encoder.fit_transform(X)\n",
    "    X_preprocessed = discretizer.fit_transform(X_encoded)\n",
    "\n",
    "    rule_generator = RuleGenerator(discretizer, encoder)\n",
    "    distinguisher = Distinguisher(discretizer, rule_generator, evaluator)\n",
    "    rules = distinguisher.find_rules(X_preprocessed, y, filter)\n",
    "    distinguisher.plot_rules_tree()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid comparison between dtype=category and float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 47\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39m# # Example of how to use this function:\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m# best_rule = ('Lot Area <= 8923.0', -2.180593997108389, 0.17438692098092642, 0.10150674068199841)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39m# X = pd.DataFrame({'Lot Area': [9000, 8500, 5000]})  # Example feature data\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39m# y = pd.Series([1, 0, 1])  # Example labels\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39mif\u001b[39;00m best_rule[\u001b[39m1\u001b[39m] \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 47\u001b[0m     result \u001b[39m=\u001b[39m flip_rule(best_rule[\u001b[39m0\u001b[39;49m], X, y)\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m result:\n\u001b[1;32m     49\u001b[0m         new_rule, new_recall, new_precision \u001b[39m=\u001b[39m result\n",
      "Cell \u001b[0;32mIn[57], line 23\u001b[0m, in \u001b[0;36mflip_rule\u001b[0;34m(rule, X, y)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39m# Generate the new mask using the flipped operator\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mif\u001b[39;00m new_operator \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m>\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 23\u001b[0m     mask \u001b[39m=\u001b[39m X[col] \u001b[39m>\u001b[39;49m value\n\u001b[1;32m     24\u001b[0m \u001b[39melif\u001b[39;00m new_operator \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m>=\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     25\u001b[0m     mask \u001b[39m=\u001b[39m X[col] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m value\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ml-env/lib/python3.10/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ml-env/lib/python3.10/site-packages/pandas/core/arraylike.py:56\u001b[0m, in \u001b[0;36mOpsMixin.__gt__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__gt__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__gt__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m---> 56\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmp_method(other, operator\u001b[39m.\u001b[39;49mgt)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ml-env/lib/python3.10/site-packages/pandas/core/series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6116\u001b[0m lvalues \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values\n\u001b[1;32m   6117\u001b[0m rvalues \u001b[39m=\u001b[39m extract_array(other, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, extract_range\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 6119\u001b[0m res_values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mcomparison_op(lvalues, rvalues, op)\n\u001b[1;32m   6121\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(res_values, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ml-env/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:330\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    322\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mLengths must match to compare\u001b[39m\u001b[39m\"\u001b[39m, lvalues\u001b[39m.\u001b[39mshape, rvalues\u001b[39m.\u001b[39mshape\n\u001b[1;32m    323\u001b[0m         )\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m should_extension_dispatch(lvalues, rvalues) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m    326\u001b[0m     (\u001b[39misinstance\u001b[39m(rvalues, (Timedelta, BaseOffset, Timestamp)) \u001b[39mor\u001b[39;00m right \u001b[39mis\u001b[39;00m NaT)\n\u001b[1;32m    327\u001b[0m     \u001b[39mand\u001b[39;00m lvalues\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m \u001b[39mobject\u001b[39m\n\u001b[1;32m    328\u001b[0m ):\n\u001b[1;32m    329\u001b[0m     \u001b[39m# Call the method on lvalues\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m     res_values \u001b[39m=\u001b[39m op(lvalues, rvalues)\n\u001b[1;32m    332\u001b[0m \u001b[39melif\u001b[39;00m is_scalar(rvalues) \u001b[39mand\u001b[39;00m isna(rvalues):  \u001b[39m# TODO: but not pd.NA?\u001b[39;00m\n\u001b[1;32m    333\u001b[0m     \u001b[39m# numpy does not like comparisons vs None\u001b[39;00m\n\u001b[1;32m    334\u001b[0m     \u001b[39mif\u001b[39;00m op \u001b[39mis\u001b[39;00m operator\u001b[39m.\u001b[39mne:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ml-env/lib/python3.10/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ml-env/lib/python3.10/site-packages/pandas/core/arrays/categorical.py:173\u001b[0m, in \u001b[0;36m_cat_compare_op.<locals>.func\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[39mreturn\u001b[39;00m ret\n\u001b[1;32m    172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m         \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49minvalid_comparison(\u001b[39mself\u001b[39;49m, other, op)\n\u001b[1;32m    174\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     \u001b[39m# allow categorical vs object dtype array comparisons for equality\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     \u001b[39m# these are only positional comparisons\u001b[39;00m\n\u001b[1;32m    177\u001b[0m     \u001b[39mif\u001b[39;00m opname \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39m__eq__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m__ne__\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ml-env/lib/python3.10/site-packages/pandas/core/ops/invalid.py:40\u001b[0m, in \u001b[0;36minvalid_comparison\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     typ \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(right)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid comparison between dtype=\u001b[39m\u001b[39m{\u001b[39;00mleft\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00mtyp\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[39mreturn\u001b[39;00m res_values\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid comparison between dtype=category and float"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "def flip_rule(rule, X, y):\n",
    "    # More robust rule parsing\n",
    "    for op in [\"<=\", \">=\", \">\", \"<\"]:  # Search for these operators\n",
    "        if op in rule:\n",
    "            parts = rule.split(op)\n",
    "            col = parts[0].strip()\n",
    "            value = float(parts[1].strip())\n",
    "            break\n",
    "    else:\n",
    "        return None  # If no operator is found, return None\n",
    "\n",
    "    # Map operators to their flipped counterparts\n",
    "    operator_flips = {\"<=\": \">\", \">=\": \"<\", \">\": \"<=\", \"<\": \">=\"}\n",
    "    new_operator = operator_flips.get(op)\n",
    "    if new_operator is None:\n",
    "        return None  # If the operator is not recognized, return None\n",
    "\n",
    "    # Generate the new mask using the flipped operator\n",
    "    if new_operator == \">\":\n",
    "        mask = X[col] > value\n",
    "    elif new_operator == \">=\":\n",
    "        mask = X[col] >= value\n",
    "    elif new_operator == \"<\":\n",
    "        mask = X[col] < value\n",
    "    elif new_operator == \"<=\":\n",
    "        mask = X[col] <= value\n",
    "\n",
    "    # Calculate metrics\n",
    "    y_pred = mask.astype(int)\n",
    "    recall = recall_score(y, y_pred, zero_division=0)\n",
    "    precision = precision_score(y, y_pred, zero_division=0)\n",
    "\n",
    "    # Construct the new rule description\n",
    "    new_rule = f\"{col} {new_operator} {value}\"\n",
    "    \n",
    "    return new_rule, recall, precision\n",
    "\n",
    "# # Example of how to use this function:\n",
    "# best_rule = ('Lot Area <= 8923.0', -2.180593997108389, 0.17438692098092642, 0.10150674068199841)\n",
    "# X = pd.DataFrame({'Lot Area': [9000, 8500, 5000]})  # Example feature data\n",
    "# y = pd.Series([1, 0, 1])  # Example labels\n",
    "\n",
    "if best_rule[1] < 0:\n",
    "    result = flip_rule(best_rule[0], X, y)\n",
    "    if result:\n",
    "        new_rule, new_recall, new_precision = result\n",
    "        new_score = abs(best_rule[1])  # Take the absolute value of the original score\n",
    "        print(f\"New Best Rule: ({new_rule}, {new_score}, {new_recall}, {new_precision})\")\n",
    "    else:\n",
    "        print(\"Failed to flip the rule due to invalid format or operator.\")\n",
    "else:\n",
    "    print(\"Best rule does not require flipping:\", best_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Rules:\n",
      "['`sepal_width` <= 2.4', {'recall': 0.21621621621621623, 'precision': 0.8, 'WoE': 1.3862943611198906}]\n",
      "['(`sepal_width` <= 2.4 & `sepal_length` > 4.5)', {'recall': 1.0, 'precision': 0.8888888888888888, 'WoE': 2.0794415416798357}]\n",
      "['(`sepal_width` > 2.4 & `sepal_width` <= 2.6)', {'recall': 0.20689655172413793, 'precision': 0.6666666666666666, 'WoE': 0.6931471805599453}]\n",
      "['((`sepal_width` > 2.4 & `sepal_width` <= 2.6) & `petal_length` <= 4.9)', {'recall': 1.0, 'precision': 0.8571428571428571, 'WoE': 1.791759469228055}]\n",
      "['(`sepal_width` > 2.6 & `sepal_width` <= 2.7)', {'recall': 0.17391304347826086, 'precision': 0.5714285714285714, 'WoE': 0.28768207245178085}]\n",
      "['((`sepal_width` > 2.6 & `sepal_width` <= 2.7) & `sepal_length` <= 6.0)', {'recall': 1.0, 'precision': 0.8, 'WoE': 1.3862943611198906}]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from math import log\n",
    "\n",
    "class Distinguisher:\n",
    "    def __init__(self, n_bins=5, bin_strategy=\"quantile\", min_recall=0.05, min_precision=0.0, tol=0.01, beam_width=1):\n",
    "        self.n_bins = n_bins\n",
    "        self.bin_strategy = bin_strategy\n",
    "        self.min_recall = min_recall\n",
    "        self.min_precision = min_precision\n",
    "        self.tol = tol\n",
    "        self.beam_width = beam_width\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        self.columns = X.columns\n",
    "        self.discretizers = {}\n",
    "        X_filled = X.fillna({col: f\"NA_{col}\" for col in X.columns})\n",
    "        for col in X_filled.columns:\n",
    "            if X_filled[col].dtype == \"object\" or X_filled[col].dtype.name == \"category\":\n",
    "                X_filled[col] = X_filled[col].astype(str)\n",
    "                self.discretizers[col] = None\n",
    "            else:\n",
    "                disc = KBinsDiscretizer(n_bins=self.n_bins, encode=\"ordinal\", strategy=self.bin_strategy)\n",
    "                self.discretizers[col] = disc.fit(X_filled[[col]])\n",
    "        return self.transform(X_filled)\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_transformed = pd.DataFrame(index=X.index)\n",
    "        X_filled = X.fillna({col: f\"NA_{col}\" for col in X.columns})\n",
    "        for col in X_filled.columns:\n",
    "            if self.discretizers[col] is None:\n",
    "                X_transformed[col] = X_filled[col]\n",
    "            else:\n",
    "                transformed = self.discretizers[col].transform(X_filled[[col]])\n",
    "                X_transformed[col] = transformed.flatten()\n",
    "        return X_transformed\n",
    "\n",
    "    def compute_WoE(self, y):\n",
    "        p_total = np.sum(y == 1)\n",
    "        n_total = np.sum(y == 0)\n",
    "        if p_total == 0 or n_total == 0:\n",
    "            return 0  # Avoid division by zero\n",
    "        return log((p_total / (p_total + n_total)) / (n_total / (p_total + n_total)))\n",
    "\n",
    "    def find_best_rule(self, X, y, min_samples, best_score):\n",
    "        best_rule = None\n",
    "        for col in X.columns:\n",
    "            values = np.unique(X[col])\n",
    "            thresholds = np.concatenate([values, [max(values) + 1]])\n",
    "            for val in thresholds:\n",
    "                for operator in [\"<=\", \">\"]:\n",
    "                    rule = f\"`{col}` {operator} {val}\"\n",
    "                    mask = X.eval(rule)\n",
    "                    if mask.sum() <= min_samples:\n",
    "                        continue\n",
    "                    score = self.compute_WoE(y[mask])\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_rule = rule\n",
    "        return best_rule, best_score\n",
    "\n",
    "    def get_opposite_rule(self, rule):\n",
    "        # Assumes rules are of the form '`column` <= value' or '`column` > value'\n",
    "        if '<=' in rule:\n",
    "            column, value = rule.split(' <= ')\n",
    "            return f'{column} > {value}'\n",
    "        elif '>' in rule:\n",
    "            column, value = rule.split(' > ')\n",
    "            return f'{column} <= {value}'\n",
    "        return None\n",
    "    \n",
    "    def generate_rules(self, X, y, current_rule='', rules=[], applied_rules=set(), depth=0, baseline_woe=None):\n",
    "        if depth > 5 or not X.size:\n",
    "            return rules\n",
    "        if baseline_woe is None:\n",
    "            baseline_woe = self.compute_WoE(y)  # Calculate baseline WoE for the entire dataset at the start\n",
    "        \n",
    "        min_samples = int(len(X) * self.min_recall)\n",
    "        rule, score = self.find_best_rule(X, y, min_samples, baseline_woe)\n",
    "        rule_mask = X.eval(rule)\n",
    "        if rule is None or rule in applied_rules:  # Ensure rule is valid and impactful\n",
    "            return rules\n",
    "\n",
    "        applied_rules.add(rule)  # Mark this rule as applied\n",
    "        recall = y[rule_mask].sum() / y.sum()\n",
    "        precision = y[rule_mask].sum() / rule_mask.sum()\n",
    "        rule_woe = self.compute_WoE(y[rule_mask])\n",
    "\n",
    "        if recall >= self.min_recall and precision >= self.min_precision and rule_woe > baseline_woe:\n",
    "            new_rule = f\"({current_rule} & {rule})\" if current_rule else rule\n",
    "            rules.append([new_rule, {'recall': recall, 'precision': precision, 'WoE': rule_woe}])\n",
    "            # Recurse on both partitions with the updated baseline WoE\n",
    "            self.generate_rules(X[rule_mask], y[rule_mask], new_rule, rules, applied_rules, depth + 1)\n",
    "            self.generate_rules(X[~rule_mask], y[~rule_mask], self.get_opposite_rule(rule), rules, applied_rules, depth + 1)\n",
    "\n",
    "        return rules\n",
    "\n",
    "    def get_opposite_rule(self, rule):\n",
    "        # Assumes rules are of the form 'column <= value' or 'column > value'\n",
    "        if '<=' in rule:\n",
    "            column, value = rule.split(' <= ')\n",
    "            return f'{column.strip()} > {value.strip()}'\n",
    "        elif '>' in rule:\n",
    "            column, value = rule.split(' > ')\n",
    "            return f'{column.strip()} <= {value.strip()}'\n",
    "        return None\n",
    "\n",
    "# Usage of the class\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = (iris.target == 1).astype(int)  # Binary classification: 1 if 'setosa', 0 otherwise\n",
    "X.columns = [col.replace(\" (cm)\", \"\").replace(\" \", \"_\") for col in X.columns]\n",
    "df = X.copy()\n",
    "df[\"target\"] = y.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "distinguisher = Distinguisher(n_bins=5, min_recall=0.01, bin_strategy=\"quantile\")\n",
    "X_train_transformed = distinguisher.fit_transform(X_train)\n",
    "rules = distinguisher.generate_rules(X_train, y_train)\n",
    "print(\"Generated Rules:\")\n",
    "for rule in rules:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Order             float64\n",
       "PID               float64\n",
       "MS SubClass       float64\n",
       "MS Zoning         float64\n",
       "Lot Frontage      float64\n",
       "                   ...   \n",
       "Misc Val          float64\n",
       "Mo Sold           float64\n",
       "Yr Sold           float64\n",
       "Sale Type         float64\n",
       "Sale Condition    float64\n",
       "Length: 81, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Rules:\n",
      "['`sepal_width` <= 2.4', {'recall': 0.21621621621621623, 'precision': 0.8, 'WoE': 1.3862943611198906}]\n",
      "['(`sepal_width` <= 2.4 & `sepal_length` > 4.5)', {'recall': 1.0, 'precision': 0.8888888888888888, 'WoE': 2.0794415416798357}]\n",
      "['(`sepal_width` > 2.4 & `sepal_width` <= 2.6)', {'recall': 0.20689655172413793, 'precision': 0.6666666666666666, 'WoE': 0.6931471805599453}]\n",
      "['((`sepal_width` > 2.4 & `sepal_width` <= 2.6) & `petal_length` <= 4.9)', {'recall': 1.0, 'precision': 0.8571428571428571, 'WoE': 1.791759469228055}]\n",
      "['(`sepal_width` > 2.6 & `sepal_width` <= 2.7)', {'recall': 0.17391304347826086, 'precision': 0.5714285714285714, 'WoE': 0.28768207245178085}]\n",
      "['((`sepal_width` > 2.6 & `sepal_width` <= 2.7) & `sepal_length` <= 6.0)', {'recall': 1.0, 'precision': 0.8, 'WoE': 1.3862943611198906}]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from math import log\n",
    "\n",
    "class Distinguisher:\n",
    "    def __init__(self, n_bins=5, bin_strategy=\"quantile\", min_recall=0.05, min_precision=0.0, tol=0.01, beam_width=1):\n",
    "        self.n_bins = n_bins\n",
    "        self.bin_strategy = bin_strategy\n",
    "        self.min_recall = min_recall\n",
    "        self.min_precision = min_precision\n",
    "        self.tol = tol\n",
    "        self.beam_width = beam_width\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        self.columns = X.columns\n",
    "        self.discretizers = {}\n",
    "        X_filled = X.fillna({col: f\"NA_{col}\" for col in X.columns})\n",
    "        for col in X_filled.columns:\n",
    "            if X_filled[col].dtype == \"object\" or X_filled[col].dtype.name == \"category\":\n",
    "                X_filled[col] = X_filled[col].astype(str)\n",
    "                self.discretizers[col] = None\n",
    "            else:\n",
    "                disc = KBinsDiscretizer(n_bins=self.n_bins, encode=\"ordinal\", strategy=self.bin_strategy)\n",
    "                self.discretizers[col] = disc.fit(X_filled[[col]])\n",
    "        return self.transform(X_filled)\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_transformed = pd.DataFrame(index=X.index)\n",
    "        X_filled = X.fillna({col: f\"NA_{col}\" for col in X.columns})\n",
    "        for col in X_filled.columns:\n",
    "            if self.discretizers[col] is None:\n",
    "                X_transformed[col] = X_filled[col]\n",
    "            else:\n",
    "                transformed = self.discretizers[col].transform(X_filled[[col]])\n",
    "                X_transformed[col] = transformed.flatten()\n",
    "        return X_transformed\n",
    "\n",
    "    def compute_WoE(self, y):\n",
    "        p_total = np.sum(y == 1)\n",
    "        n_total = np.sum(y == 0)\n",
    "        if p_total == 0 or n_total == 0:\n",
    "            return 0  # Avoid division by zero\n",
    "        return log((p_total / (p_total + n_total)) / (n_total / (p_total + n_total)))\n",
    "\n",
    "    def find_best_rule(self, X, y, min_samples, best_score):\n",
    "        best_rule = None\n",
    "        for col in X.columns:\n",
    "            values = np.unique(X[col])\n",
    "            thresholds = np.concatenate([values, [max(values) + 1]])\n",
    "            for val in thresholds:\n",
    "                for operator in [\"<=\", \">\"]:\n",
    "                    rule = f\"`{col}` {operator} {val}\"\n",
    "                    mask = X.eval(rule)\n",
    "                    if mask.sum() <= min_samples:\n",
    "                        continue\n",
    "                    score = self.compute_WoE(y[mask])\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_rule = rule\n",
    "        return best_rule, best_score\n",
    "\n",
    "    def get_opposite_rule(self, rule):\n",
    "        # Assumes rules are of the form '`column` <= value' or '`column` > value'\n",
    "        if '<=' in rule:\n",
    "            column, value = rule.split(' <= ')\n",
    "            return f'{column} > {value}'\n",
    "        elif '>' in rule:\n",
    "            column, value = rule.split(' > ')\n",
    "            return f'{column} <= {value}'\n",
    "        return None\n",
    "    \n",
    "    def generate_rules(self, X, y, current_rule='', rules=[], applied_rules=set(), depth=0, baseline_woe=None):\n",
    "        if depth > 5 or not X.size:\n",
    "            return rules\n",
    "        if baseline_woe is None:\n",
    "            baseline_woe = self.compute_WoE(y)  # Calculate baseline WoE for the entire dataset at the start\n",
    "        \n",
    "        min_samples = int(len(X) * self.min_recall)\n",
    "        rule, score = self.find_best_rule(X, y, min_samples, baseline_woe)\n",
    "        rule_mask = X.eval(rule)\n",
    "        if rule is None or rule in applied_rules:  # Ensure rule is valid and impactful\n",
    "            return rules\n",
    "\n",
    "        applied_rules.add(rule)  # Mark this rule as applied\n",
    "        recall = y[rule_mask].sum() / y.sum()\n",
    "        precision = y[rule_mask].sum() / rule_mask.sum()\n",
    "        rule_woe = self.compute_WoE(y[rule_mask])\n",
    "\n",
    "        if recall >= self.min_recall and precision >= self.min_precision and rule_woe > baseline_woe:\n",
    "            new_rule = f\"({current_rule} & {rule})\" if current_rule else rule\n",
    "            rules.append([new_rule, {'recall': recall, 'precision': precision, 'WoE': rule_woe}])\n",
    "            # Recurse on both partitions with the updated baseline WoE\n",
    "            self.generate_rules(X[rule_mask], y[rule_mask], new_rule, rules, applied_rules, depth + 1)\n",
    "            self.generate_rules(X[~rule_mask], y[~rule_mask], self.get_opposite_rule(rule), rules, applied_rules, depth + 1)\n",
    "\n",
    "        return rules\n",
    "\n",
    "    def get_opposite_rule(self, rule):\n",
    "        # Assumes rules are of the form 'column <= value' or 'column > value'\n",
    "        if '<=' in rule:\n",
    "            column, value = rule.split(' <= ')\n",
    "            return f'{column.strip()} > {value.strip()}'\n",
    "        elif '>' in rule:\n",
    "            column, value = rule.split(' > ')\n",
    "            return f'{column.strip()} <= {value.strip()}'\n",
    "        return None\n",
    "\n",
    "# Usage of the class\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = (iris.target == 1).astype(int)  # Binary classification: 1 if 'setosa', 0 otherwise\n",
    "X.columns = [col.replace(\" (cm)\", \"\").replace(\" \", \"_\") for col in X.columns]\n",
    "df = X.copy()\n",
    "df[\"target\"] = y.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "distinguisher = Distinguisher(n_bins=5, min_recall=0.01, bin_strategy=\"quantile\")\n",
    "X_train_transformed = distinguisher.fit_transform(X_train)\n",
    "rules = distinguisher.generate_rules(X_train, y_train)\n",
    "print(\"Generated Rules:\")\n",
    "for rule in rules:\n",
    "    print(rule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
